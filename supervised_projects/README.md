# 🧠 Linear Regression from Scratch — A Comparative Approach

📌 Description
This project implements Linear Regression from scratch using Gradient Descent and compares the results with Scikit-learn's LinearRegression and SGDRegressor.
It aims to demonstrate how linear regression works under the hood, how gradient descent optimizes parameters, and how it compares to modern machine learning libraries.

📊 What This Project Covers
💡 Understanding the concept of Mean Squared Error (MSE) as a cost function
📈 Visualizing the fitted line on synthetic data
🔍 Comparing custom implementation with:
LinearRegression (closed-form)
SGDRegressor (gradient descent)
📉 Evaluating and comparing loss (MSE) between models

📁 Files
linear_regression_scratch.ipynb — Main notebook with code, explanations and comparisons
README.md — You're here!

⚙️ Technologies Used
Python 3
NumPy
Pandas
Matplotlib 
Scikit-learn

📌 Sample Output
Comparison of model coefficients
Graphs showing fitted lines and convergence
MSE values for each method

✍️ Author
**Nicolas Morganti**  
  Master's student in Applied Probabilities and Statistics  
  Passionate about machine learning, finance, and data science  
  🔗 [LinkedIn Profile](https://www.linkedin.com/in/nicolas-morganti)
